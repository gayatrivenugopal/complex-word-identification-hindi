{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['frequency', 'length', 'n_avg_hypernyms', 'n_avg_hyponyms',\n",
      "       'n_avg_synonyms', 'n_consonantconjuncts', 'n_consonants', 'n_hypernyms',\n",
      "       'n_hyponyms', 'n_syllables', 'n_synonyms', 'n_synsets', 'n_vowels',\n",
      "       'label'],\n",
      "      dtype='object')\n",
      "[(0, 6260), (1, 1488)]\n",
      "[(0, 1488), (1, 1488)]\n",
      "0     0.127769\n",
      "1     0.050690\n",
      "2     0.086586\n",
      "3     0.114143\n",
      "4     0.077578\n",
      "5     0.044267\n",
      "6     0.050457\n",
      "7     0.074138\n",
      "8     0.088959\n",
      "9     0.060484\n",
      "10    0.107988\n",
      "11    0.067683\n",
      "12    0.049258\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3081\n",
       "                \n",
       "                    &plusmn; 0.0140\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_avg_hyponyms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2249\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_synonyms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2053\n",
       "                \n",
       "                    &plusmn; 0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_avg_hypernyms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.85%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1880\n",
       "                \n",
       "                    &plusmn; 0.0112\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_synsets\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1788\n",
       "                \n",
       "                    &plusmn; 0.0054\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                frequency\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1577\n",
       "                \n",
       "                    &plusmn; 0.0110\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_hyponyms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1407\n",
       "                \n",
       "                    &plusmn; 0.0054\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_hypernyms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0982\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_syllables\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0931\n",
       "                \n",
       "                    &plusmn; 0.0103\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_avg_synonyms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0876\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_consonants\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0780\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                length\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.68%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0733\n",
       "                \n",
       "                    &plusmn; 0.0044\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_consonantconjuncts\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0642\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                n_vowels\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "#from xgboost import plot_importance\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "#from data_tests import *\n",
    "from models import get_model\n",
    "from evaluation import get_accuracy\n",
    "\n",
    "def ensemble_learning(X, y, baseline = -1, model_num = None, resample = 0, feature_set = None, n_features = 0, feature_importance = 0, average_method='macro', path= None):\n",
    "    \"\"\"\n",
    "    Store the results calculated according to the arguments and store them in a file.\n",
    "    Arguments:\n",
    "    X (dataframe): examples\n",
    "    y (dataframe): target/label\n",
    "    baseline (int): -1 for no baseline, 1 for all predictions as 1, 0 for all predictions as 0\n",
    "    model_num (int): classification model\n",
    "    1: \n",
    "    2:\n",
    "    3:\n",
    "    4:\n",
    "    5:\n",
    "    6:\n",
    "    resample (int): -1 for undersampling, 1 for oversampling and 0 for no resampling\n",
    "    feature_set (list): list of features to be considered\n",
    "    n_features (int): the number of features to be considered at a time for classification/importance\n",
    "    feature_importance (int): 0 for absent, 1 for present\n",
    "    average_method: macro by default\n",
    "    path: the path to the directory where the recordings should be stored\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "   \n",
    "    #prepare the dictionary to be written to the file\n",
    "    data_dict = dict()\n",
    "    dir_name = path + str(time.time())\n",
    "    os.mkdir(dir_name)\n",
    "    \n",
    "    #open the config file for writing\n",
    "    config_file = open(dir_name + '/config.json', 'w')\n",
    "\n",
    "    data_dict =  {'model_num':model_num}\n",
    "    data_dict =  {'baseline':baseline}\n",
    "    data_dict.update({'resample':resample})\n",
    "    data_dict.update({'feature_set':feature_set})\n",
    "    data_dict.update({'n_features':n_features})\n",
    "    data_dict.update({'feature_importance':feature_importance})\n",
    "    \n",
    "    #create test set labels for the baseline if applicable\n",
    "    if baseline == 0:\n",
    "        y_test = y_test.replace(1,0)\n",
    "    elif baseline == 1:\n",
    "        y_test = y_test.replace(0,1)\n",
    "            \n",
    "    #resample the training set (if applicable)\n",
    "    if resample == -1:\n",
    "        #undersample\n",
    "        '''NearMiss 3 . NearMiss-3 is a 2-step algorithm: first, for each minority sample, \n",
    "        their :m nearest-neighbors will be kept; then, the majority samples selected are the \n",
    "        on for which the average distance to the k nearest neighbors is the largest.'''\n",
    "        nm = NearMiss(version=3)\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        X_resampled, y_resampled = nm.fit_resample(X_train, y_train)\n",
    "        X_train = X_resampled\n",
    "        y_train = y_resampled\n",
    "        print(str(sorted(Counter(y_train).items())))\n",
    "    elif resample == 1:\n",
    "        #oversample\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "        X_train = X_resampled\n",
    "        y_train = y_resampled\n",
    "        print(sorted(Counter(y_resampled).items()))\n",
    "    #write the training dataset class distribution to the file\n",
    "    file = open(dir_name + '/train_val_dist.csv', 'a')\n",
    "    file.write(str(sorted(Counter(y_train).items())))\n",
    "    file.write('\\n')\n",
    "    file.close()\n",
    "\n",
    "    model = get_model(model_num)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "        \n",
    "    #TODO: evaluation\n",
    "    accuracy = get_accuracy(y_test, y_pred)\n",
    "    data_dict['accuracy'] = accuracy * 100\n",
    "    score = model.score(X_test,y_test)\n",
    "    data_dict['score'] = score\n",
    "\n",
    "    if feature_importance == 1:\n",
    "        feat_importances = pd.Series(model.feature_importances_, index=feature_set)\n",
    "        print(feat_importances)\n",
    "        feat_importances.nlargest(20).plot(kind='barh')\n",
    "        #plot_importance(model)\n",
    "        plt.show()\n",
    "\n",
    "        perm = PermutationImportance(model, random_state=1).fit(X_train, y_train)\n",
    "        display(eli5.show_weights(perm, feature_names = X_train.columns.tolist()))\n",
    "        \n",
    "\n",
    "        #write the training dataset class distribution to the file\n",
    "        file = open(dir_name + '/feature_importances.csv', 'a')\n",
    "        file.write(feat_importances.to_string())\n",
    "        file.write('\\n')\n",
    "        file.close()\n",
    "\n",
    "        #write the permutation importance values to the file\n",
    "        file = open(dir_name + '/permutation_feature_importances.csv', 'a')\n",
    "        file.write(str(perm))\n",
    "        file.write('\\n')\n",
    "        file.close()\n",
    "\n",
    "    json.dump(data_dict, config_file)\n",
    "    config_file.close()\n",
    "\n",
    "data = pd.read_csv('/opt/PhD/Work/JHWNL_1_2/Data/CleanedData/Basic Binary Classification/DataForClassification.csv')\n",
    "#print(data.iloc[:, 1:-1].head())\n",
    "del data['word']\n",
    "print(data.columns)\n",
    "ensemble_learning(data.iloc[:, :-1], data.label, baseline = -1, model_num = 1, feature_importance=1, resample = -1, path = '/opt/PhD/Work/JHWNL_1_2/Data/Analysis/')\n",
    "#TODO: evaluation\n",
    "#TODO: permutation importance for each model\n",
    "#TODO: learning curve\n",
    "#TODO: run this in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
