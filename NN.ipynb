{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBgM-V2m06xS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc0f255-6016-42d5-c155-7a574ac06491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Colab/CleanedData/'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fasttext"
      ],
      "metadata": {
        "id": "yeCXH6K1xxld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2c5ed1-f6f5-44a3-b113-9654c1a8e9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 5.0 MB/s \n",
            "\u001b[?25h  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Source: https://www.kaggle.com/jungealexander/word2vec-and-random-forest-classification\n",
        "\n",
        "import fasttext\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn import preprocessing\n",
        "\n",
        "file = '/content/drive/MyDrive/Colab/AI4Bharat/indicnlp.v1.hi.bin'\n",
        "#path = '/content/drive/MyDrive/Colab/Embeddings+All/'\n",
        "#analysis_path = '/content/drive/MyDrive/Colab/Embeddings+All/Analysis/'\n",
        "#read the train and test files in majority dataset and insert the embeddings in the files\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab/CleanedData/RankedClassification/train_updated.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab/CleanedData/RankedClassification/test_updated.csv')\n",
        "\n",
        "model = fasttext.load_model(file)\n",
        "\n",
        "def vectorise(key):\n",
        "    try:\n",
        "        return model.get_word_vector(key)\n",
        "    except:\n",
        "\t      return [0]*300 #dimensions\n",
        "\n",
        "X_train = train_df[['word']]\n",
        "y_train = train_df['label']\n",
        "\n",
        "X_test = test_df[['word']]\n",
        "y_test = test_df['label']\n",
        "\n",
        "#extract normalised embeddings\n",
        "df = X_train.copy()\n",
        "df['vector'] = X_train['word'].apply(vectorise)\n",
        "X_train_vector = pd.DataFrame(df['vector'].values.tolist())\n",
        "scaler = preprocessing.MinMaxScaler().fit(X_train_vector)\n",
        "X_train_vector =  pd.DataFrame(scaler.transform(X_train_vector))\n",
        "train_df.index = X_train_vector.index\n",
        "\n",
        "df = X_test.copy()\n",
        "df['vector'] = X_test['word'].apply(vectorise)\n",
        "X_test_vector = pd.DataFrame(df['vector'].values.tolist())\n",
        "scaler = preprocessing.MinMaxScaler().fit(X_test_vector)\n",
        "X_test_vector = pd.DataFrame(scaler.transform(X_test_vector))\n",
        "test_df.index = X_test_vector.index\n",
        "\n",
        "columns = ['length', 'n_synsets', 'n_synonyms', 'n_consonants', 'n_vowels', 'n_hypernyms', 'n_hyponyms', 'n_consonantconjuncts', 'n_syllables', 'frequency']\n",
        "\n",
        "for column in columns:\n",
        "    X_train_vector[column] = train_df[[column]]\n",
        "    X_test_vector[column] = test_df[[column]]\n",
        "#print(X_train_vector.columns, X_test_vector.columns)\n",
        "\n",
        "#X_train_vector.to_csv(path + \"trainembeddingsfreq.csv\")\n",
        "#X_test_vector.to_csv(path + \"testembeddingsfreq.csv\")\n",
        "\n",
        "\n",
        "#classify(path, X_train_vector, y_train)\n",
        "#test(X_test_vector, y_test, path, analysis_path, 'test')\n"
      ],
      "metadata": {
        "id": "OyozTHbfxQFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff5edf7-8c16-4f3a-c110-b51c71d99c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "dX6INYPn2qJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81595e74-57a4-4f68-c852-84ff62cd4d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.9.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (175.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 175.5 MB 9.3 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.10.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 105 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cpu) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cpu) (1.21.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cpu) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0+cpu which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cpu torchaudio-0.9.0 torchvision-0.10.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td\n",
        "\n",
        "# Set random seed for reproducability\n",
        "torch.manual_seed(0)\n",
        "\n",
        "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
      ],
      "metadata": {
        "id": "VT8dskPV2nsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090a4d4b-1b49-4933-d2e0-9eac29ff0218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported - ready to use PyTorch 1.9.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(X_train_vector.values).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=20,\n",
        "    shuffle=False, num_workers=1)\n",
        "\n",
        "#features = [\"length\",\"n_synsets\",\"n_synonyms\",\"n_consonants\",\"n_vowels\",\"n_hypernyms\",\"n_hyponyms\",\"n_consonantconjuncts\",\"n_syllables\",\"frequency\"]\n",
        "features = range(1, 311)\n",
        "label = \"label\"\n",
        "cwi_classes = [1,0]\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(X_test_vector.values).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=20,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "id": "UobnjsoR12tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db39de36-151e-444f-e1ba-e1ce2f0b8847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a neural network\n",
        "\n",
        "# Number of hidden layer nodes\n",
        "hl = 100\n",
        "\n",
        "# Define the neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(len(features), hl)\n",
        "        self.fc2 = nn.Linear(hl, hl)\n",
        "        self.fc3 = nn.Linear(hl, len(cwi_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Create a model instance from the network\n",
        "model = NeuralNet()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "WV_heQaF2B5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5db35b5-4032-4307-d043-29efeb976b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet(\n",
            "  (fc1): Linear(in_features=310, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        #feedforward\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backpropagate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Return average loss\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        target_true = 0\n",
        "        predicted_true = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target).item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "\n",
        "           \n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f})%\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss\n",
        "\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "id": "olZMlL_L2Ci8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ec9a812-87ff-4965-c127-f93f232676f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.405266\n",
            "Validation set: Average loss: 3.612324, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 1.039616\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.693147\n",
            "Validation set: Average loss: 0.693147, Accuracy: 1280/2190 (58)%\n",
            "\n",
            "Epoch: 13\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-93a314a35d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Feed training data into the model to optimize the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Feed the test data into the model to check its performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-93a314a35d62>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#feedforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0;31m# wrong, we set a timeout and if the workers fail to join,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                     \u001b[0;31m# they are killed in the `finally` block.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Review training and validation loss\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(epoch_nums, training_loss)\n",
        "plt.plot(epoch_nums, validation_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "#View the learned weights and biases\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\n\", model.state_dict()[param_tensor].numpy())"
      ],
      "metadata": {
        "id": "i6JkJl7e2Mhc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2033
        },
        "outputId": "d78b269b-bcc7-4854-def6-5992184b49bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight \n",
            " [[-0.00042522  0.03046795 -0.04674582 ...  0.02419115  0.02248169\n",
            "  -0.00714943]\n",
            " [-0.05256627 -0.01476084  0.01372027 ...  0.00203571  0.04231996\n",
            "   0.00162961]\n",
            " [-0.02027166  0.05973462  0.01944802 ... -0.03834351  0.04901766\n",
            "   0.02382735]\n",
            " ...\n",
            " [ 0.03603877 -0.02486854 -0.00972376 ... -0.00216061 -0.0051849\n",
            "   0.0515995 ]\n",
            " [ 0.04607052  0.04527395 -0.02967917 ...  0.03281916  0.00893984\n",
            "   0.00689949]\n",
            " [-0.01845303  0.00643366  0.02358667 ... -0.03017515 -0.01964898\n",
            "   0.03123358]]\n",
            "fc1.bias \n",
            " [ 0.02592768  0.01472741 -0.03339588 -0.02263921 -0.0436551   0.04901784\n",
            "  0.03155893 -0.01357437  0.01730591 -0.05013862  0.00615896  0.03703655\n",
            " -0.05089536  0.01359677 -0.01088788 -0.01857476 -0.03354496  0.01680246\n",
            "  0.00597843  0.04411779 -0.05464324 -0.04273502 -0.01156253  0.01242688\n",
            "  0.02896088 -0.04323313 -0.05714671 -0.00695802  0.01217519 -0.00549499\n",
            " -0.00183299  0.01316566  0.03495137 -0.00900456  0.00652294  0.02103885\n",
            "  0.04867921 -0.03014768 -0.01570873  0.04742545  0.01658326 -0.03372896\n",
            " -0.01719998  0.02612232  0.03285442 -0.03939416 -0.04092237 -0.04587054\n",
            " -0.05552812  0.02422426  0.02497999 -0.00280852 -0.02317829 -0.00517828\n",
            "  0.00473202  0.01546009  0.0623823  -0.06246388 -0.05839676  0.04466762\n",
            "  0.00815733  0.00226061  0.03094206  0.04508829 -0.02749542  0.02952338\n",
            " -0.03064696 -0.04093977  0.00069259  0.03885591 -0.01173387 -0.04332568\n",
            "  0.04120285 -0.00238365  0.0404712   0.01213607  0.03827659 -0.00121572\n",
            "  0.03583055  0.05610144 -0.05478278 -0.05285183 -0.04334081 -0.06166246\n",
            "  0.0074801   0.04877476  0.05112036 -0.01924434  0.02586118 -0.01484959\n",
            " -0.05476635 -0.03106976  0.01551828  0.05939889  0.04674171 -0.0058168\n",
            " -0.04680445 -0.04720322 -0.00622735 -0.0132902 ]\n",
            "fc2.weight \n",
            " [[ 0.04646338  0.08823472 -0.04899089 ...  0.03510276  0.02553167\n",
            "   0.03568255]\n",
            " [ 0.09892275 -0.08130904 -0.01393173 ...  0.05705509 -0.09152907\n",
            "  -0.07498336]\n",
            " [ 0.07527599 -0.01875532  0.05741036 ...  0.05849705 -0.09149954\n",
            "  -0.01241113]\n",
            " ...\n",
            " [ 0.04711087 -0.04034742 -0.06540243 ... -0.07076535  0.08191264\n",
            "  -0.05222725]\n",
            " [ 0.08428114 -0.02012905 -0.04234764 ... -0.06279811  0.07129651\n",
            "   0.02316096]\n",
            " [-0.01768874  0.02261484  0.04918224 ... -0.08325922 -0.0014617\n",
            "  -0.08486088]]\n",
            "fc2.bias \n",
            " [-0.03872814  0.08318068  0.01657621  0.04225265 -0.00040911 -0.03733172\n",
            " -0.06046423 -0.08588097 -0.06748452 -0.09951706 -0.08388249  0.03176842\n",
            " -0.07105493 -0.06982502  0.00237197  0.00235757  0.01372098  0.02800565\n",
            " -0.06884125  0.03219466 -0.03439371  0.0808396  -0.07451066  0.08676074\n",
            " -0.00413087 -0.02743911  0.00124629  0.0158976   0.02259729 -0.0408795\n",
            " -0.04963315 -0.10504059 -0.04441258 -0.04126259 -0.00867364  0.06197157\n",
            " -0.03106899 -0.04525129  0.03896165  0.08776854 -0.07394302  0.05523128\n",
            " -0.0384156  -0.0686674  -0.02095124  0.01182206 -0.00039409 -0.02954688\n",
            " -0.08525195  0.03389668 -0.09628085 -0.05174701  0.07029903  0.07179727\n",
            " -0.07913804  0.00244614  0.0423327   0.03144823 -0.00470929  0.01610826\n",
            " -0.08439729 -0.03552935 -0.01577334 -0.10415204 -0.0983422   0.06380381\n",
            " -0.03261779 -0.05685494  0.07762711  0.05326949  0.00201783 -0.00238441\n",
            "  0.05677989  0.05008914  0.07048073  0.06291242  0.0709579  -0.04677075\n",
            " -0.08114121 -0.08802634 -0.06384673  0.06661136 -0.04741837 -0.02042655\n",
            " -0.00777951 -0.02424002 -0.02161164  0.03813967  0.02079681 -0.01520445\n",
            " -0.06185715 -0.04353776 -0.02864708  0.08778778 -0.01394442 -0.0414269\n",
            "  0.05529729  0.0723029   0.03717311 -0.06773007]\n",
            "fc3.weight \n",
            " [[ 0.07585525 -0.08089693 -0.08307409 -0.03834787  0.00510899 -0.08900988\n",
            "  -0.01021518  0.08061464  0.02893935 -0.01124452  0.08120406  0.01953121\n",
            "   0.02650251  0.00539315  0.00189463 -0.09949942  0.08437235 -0.07652803\n",
            "   0.02994888 -0.10180958 -0.06192942 -0.03815925  0.07919127  0.001035\n",
            "  -0.02004538 -0.02353672  0.00898656  0.0100427  -0.04397732 -0.04331454\n",
            "  -0.04586451  0.01542216  0.04686568 -0.05455072 -0.02246989 -0.04015467\n",
            "  -0.03933153  0.04324026 -0.0294933   0.08920204 -0.02871618  0.03930694\n",
            "   0.08591709 -0.09124227  0.02804756 -0.07055     0.02037085  0.06855991\n",
            "   0.03446944  0.04191815  0.08170468 -0.07837596  0.07827731 -0.09476501\n",
            "   0.08248376 -0.08955323  0.06464217 -0.00714595  0.06585592  0.04418608\n",
            "   0.07076123 -0.0710938   0.02827719  0.00573916  0.0616485  -0.05130435\n",
            "   0.02933762  0.0665615   0.0389959   0.09965926 -0.01234726 -0.09952246\n",
            "  -0.04045014  0.0290105  -0.04966735 -0.02037649  0.04338389  0.05085288\n",
            "   0.08189986 -0.03582909 -0.08715836  0.00185025 -0.09987483  0.03223116\n",
            "  -0.09187166 -0.06274555 -0.05155033 -0.00871527 -0.06483635  0.02582678\n",
            "   0.0713253   0.00089343  0.00518941 -0.0205422  -0.09937313 -0.07350893\n",
            "   0.0209325  -0.09731658 -0.04328463  0.00397674]\n",
            " [ 0.014911    0.00237207 -0.07486882 -0.04741527 -0.00279309  0.01538289\n",
            "  -0.01394686  0.03103348 -0.04511682  0.08942926 -0.04642767  0.07963105\n",
            "  -0.09966282  0.01176685  0.02488703 -0.00261467 -0.08373024 -0.0258246\n",
            "   0.09355269  0.03231657 -0.06435179 -0.02874738 -0.03112941 -0.02822962\n",
            "   0.01785137  0.08427159 -0.01712612  0.02173493  0.05389409 -0.02626768\n",
            "   0.00951573  0.0741991  -0.05030384 -0.02268965  0.03736424  0.00069057\n",
            "   0.0354059  -0.04522387  0.0491824   0.08107588 -0.09935009 -0.06664934\n",
            "  -0.07399725 -0.01372556  0.0345482   0.08850136 -0.09653687  0.00028687\n",
            "  -0.00905191  0.06323285 -0.05443541  0.06830449 -0.00103078 -0.08169033\n",
            "  -0.06013051  0.05159042  0.07970488 -0.05830801 -0.07377545  0.03462623\n",
            "   0.09905212 -0.00795932  0.08681094 -0.01730427 -0.07809009 -0.09824988\n",
            "  -0.08363701 -0.09485164  0.0083232  -0.09954428  0.0413937  -0.05879016\n",
            "   0.02709309 -0.00317056  0.01907045 -0.02254721 -0.04892395 -0.04923568\n",
            "   0.09651219  0.06790342 -0.07877133  0.00808642  0.08089658  0.00523943\n",
            "   0.0447592   0.08714437  0.04443184 -0.03953747 -0.05838478 -0.03935152\n",
            "  -0.00380185  0.04821167 -0.05536261 -0.0316136  -0.09513845  0.03172195\n",
            "   0.03233311 -0.03923736  0.05279941  0.0746782 ]]\n",
            "fc3.bias \n",
            " [0.04963027 0.02101635]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model performance\n",
        "\n",
        "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Set the model to evaluate mode\n",
        "model.eval()\n",
        "\n",
        "# Get predictions for the test data\n",
        "x = torch.Tensor(X_test).float()\n",
        "_, predicted = torch.max(model(x).data, 1)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, predicted.numpy())\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(cwi_classes))\n",
        "plt.xticks(tick_marks, cwi_classes, rotation=45)\n",
        "plt.yticks(tick_marks, cwi_classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wVvuJ98p2Qd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "32d112a8-9fc9-42da-df7a-5351b4f51415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cf45e2e5c492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Get predictions for the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "model_file = 'models/cwi_classifier.pt'\n",
        "torch.save(model.state_dict(), model_file)\n",
        "del model\n",
        "print('model saved as', model_file)"
      ],
      "metadata": {
        "id": "O8yLfqm02SHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the trained model\n",
        "\n",
        "# New features\n",
        "x_new = [[50.4,15.3,20,50]]\n",
        "print ('New sample: {}'.format(x_new))\n",
        "\n",
        "# Create a new model class and load weights\n",
        "model = NeuralNet()\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Get a prediction for the new data sample\n",
        "x = torch.Tensor(x_new).float()\n",
        "_, predicted = torch.max(model(x).data, 1)\n",
        "\n",
        "print('Prediction:',cwi_classes[predicted.item()])"
      ],
      "metadata": {
        "id": "lVGxKSSj2UIy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}